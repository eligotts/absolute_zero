import atexit
import builtins as _py_builtins
import inspect
import math
import os
import pickle
import queue
import re
import signal
import subprocess
import sys
import threading
import traceback
from pathlib import Path
from copy import deepcopy
from typing import Any, Callable, Dict, List, Optional, Tuple

from azr_utils.azr_logging import get_logger


# =========================
# Safe Python executor
# =========================


class _ExecutionTimeout(Exception):
    """Raised when user code exceeds the configured runtime budget."""


class _Job:
    __slots__ = ("payload", "event", "result")

    def __init__(self, payload: Dict[str, Any]):
        self.payload = payload
        self.event = threading.Event()
        self.result: Optional[Tuple[bool, Optional[List[Any]], Optional[str]]] = None

    def set_result(self, ok: bool, outputs: Optional[List[Any]], error: Optional[str]) -> None:
        self.result = (ok, outputs, error)
        self.event.set()


class AZRExecutor:
    """
    Sandboxed Python executor for single-function programs.
    - Disallows import and dangerous builtins/modules.
    - Provides a whitelisted set of builtins and math module.
    - Supports calling with single arg, *args (if input is list/tuple), or **kwargs (if input is dict).
    - Determinism check by repeated runs.
    """

    DISALLOWED_PATTERNS = [
        r"\bimport\b",
        r"__import__",
        r"\beval\s*\(",
        r"\bexec\s*\(",
        r"\bopen\s*\(",
        r"\bcompile\s*\(",
        r"\bos\b",
        r"\bsys\b",
        r"\bshutil\b",
        r"\bsubprocess\b",
        r"\bpathlib\b",
        r"\bsocket\b",
        r"\brequests\b",
        r"\burllib\b",
        r"\bhttp\b",
        r"\bjsonpickle\b",
        r"\bpickle\b",
        r"\bmarshal\b",
        r"\bctypes\b",
        r"\bimportlib\b",
        r"\bthreading\b",
        r"\bmultiprocessing\b",
        r"\brandom\b",  # disallow stochastic behavior
        r"\bnumpy\b",
        r"\bpandas\b",
        r"\btime\.sleep\s*\(",
        r"\bbuiltins\b",
        r"\bglobals\s*\(",
        r"\blocals\s*\(",
        r"\bvars\s*\(",
        r"\bsetattr\s*\(",
        r"\bdelattr\s*\(",
        r"\bgetattr\s*\(",
    ]

    ALLOWED_BUILTINS = {
        "__build_class__": _py_builtins.__build_class__,
        "abs": abs,
        "all": all,
        "any": any,
        "bool": bool,
        "chr": chr,
        "object": object,
        "type": type,
        "super": super,
        "isinstance": isinstance,
        "staticmethod": staticmethod,
        "classmethod": classmethod,
        "property": property,
        "dict": dict,
        "enumerate": enumerate,
        "filter": filter,
        "float": float,
        "int": int,
        "len": len,
        "list": list,
        "map": map,
        "max": max,
        "min": min,
        "ord": ord,
        "pow": pow,
        "range": range,
        "set": set,
        "sorted": sorted,
        "str": str,
        "sum": sum,
        "tuple": tuple,
        "zip": zip,
        "reversed": reversed,
    }

    def __init__(
        self,
        max_exec_seconds: float = 5.0,
        start_method: Optional[str] = None,
        max_workers: Optional[int] = None,
        enable_logging: bool = False,
    ):
        """Initialize the executor and a capped pool of worker subprocesses."""

        _ = start_method  # preserved for compatibility; intentionally unused
        self.enable_logging = enable_logging
        self.logger = get_logger(self.enable_logging, "AZRExecutor")
        self.max_exec_seconds = float(max_exec_seconds)
        self.start_method = "subprocess"
        self._worker_script = Path(__file__).with_name("azr_executor_worker.py")

        if max_workers is None:
            cpu_count = os.cpu_count() or 2
            max_workers = max(1, min(4, cpu_count // 2))
        self.max_workers = int(max_workers)

        self._task_queue: "queue.Queue[Optional[_Job]]" = queue.Queue()
        self._workers: List[threading.Thread] = []
        self._shutdown = False

        self._start_worker_threads()
        atexit.register(self.shutdown)

    @classmethod
    def _static_scan(cls, program: str) -> Optional[str]:
        for pat in cls.DISALLOWED_PATTERNS:
            if re.search(pat, program):
                return f"Program contains disallowed pattern: {pat}"
        return None

    @staticmethod
    def _discover_callable(env: Dict[str, Any]) -> Optional[Callable]:
        # Prefer 'f', else first callable defined by user (skip dunder)
        if "f" in env and callable(env["f"]):
            return env["f"]
        for k, v in env.items():
            if callable(v) and not k.startswith("__"):
                return v
        return None

    @staticmethod
    def _call_function(f: Callable, inp: Any) -> Any:
        sig = inspect.signature(f)
        params = list(sig.parameters.values())
        param_count = len(params)
        if param_count == 0:
            return f()
        if param_count == 1:
            single_param = params[0]
            if isinstance(inp, dict) and single_param.kind == inspect.Parameter.VAR_KEYWORD:
                return f(**inp)
            if isinstance(inp, list) and len(inp) == 1 and isinstance(inp[0], (list, dict, tuple)):
                return f(inp[0])
            return f(inp)
        if isinstance(inp, dict):
            return f(**inp)
        if isinstance(inp, (list, tuple)):
            return f(*inp)
        return f(inp)

    def compile_program(self, program: str) -> Tuple[Optional[Callable], Optional[str]]:
        err = self._static_scan(program)
        if err:
            return None, err
        safe_globals: Dict[str, Any] = {
            "__builtins__": self.ALLOWED_BUILTINS,
            "__build_class__": _py_builtins.__build_class__,
            "__name__": "__main__",
            "math": math,
        }
        try:
            exec(program, safe_globals, safe_globals)
        except Exception as exc:
            return None, f"Program exec failed: {exc}"
        func = self._discover_callable(safe_globals)
        if func is None:
            return None, "No callable function found (expected def f(...): ...)"
        try:
            setattr(func, "__azr_source__", program)
        except Exception:
            pass
        return func, None

    def run_deterministic(self, f: Callable, inp: Any, runs: int = 2) -> Tuple[bool, Optional[Any], Optional[str]]:
        runs = max(2, runs)
        program_src = getattr(f, "__azr_source__", None)
        if not isinstance(program_src, str):
            return False, None, "Missing program source for execution"
        ok, outputs, error = self._execute_with_timeout(program_src, inp, runs)
        if not ok:
            return False, None, error
        if not outputs:
            return False, None, "No output produced"
        first = outputs[0]
        for out in outputs[1:]:
            if out != first:
                return False, None, "Non-deterministic output across runs"
        return True, first, None

    def eval_output_prediction(
        self,
        code: str,
        program_input: Any,
        gold_output: Any,
        agent_output: Any,
        runs: int = 2,
    ) -> bool:
        func, err = self.compile_program(code)
        if func is None:
            return False
        ok, out, _ = self.run_deterministic(func, program_input, runs=runs)
        if not ok:
            return False
        return out == agent_output or agent_output == gold_output

    def eval_abduction_input(
        self, code: str, gold_output: Any, agent_input: Any, runs: int = 2
    ) -> bool:
        func, err = self.compile_program(code)
        if func is None:
            return False
        ok, out, _ = self.run_deterministic(func, agent_input, runs=runs)
        if not ok:
            return False
        return out == gold_output

    def eval_program_on_pairs(
        self, code: str, io_pairs: List[Tuple[Any, Any]], runs: int = 2
    ) -> bool:
        func, err = self.compile_program(code)
        if func is None:
            return False
        for inp, expected in io_pairs:
            ok, out, _ = self.run_deterministic(func, inp, runs=runs)
            if not ok or out != expected:
                return False
        return True

    def _execute_with_timeout(
        self, program: str, inp: Any, runs: int
    ) -> Tuple[bool, Optional[List[Any]], Optional[str]]:
        if not self._worker_script.exists():  # pragma: no cover - defensive
            if self.enable_logging:
                self.logger.warning("Worker script missing at %s", self._worker_script)
            return False, None, f"Worker script not found at {self._worker_script}"

        payload = {
            "program": program,
            "input": inp,
            "runs": runs,
            "timeout": self.max_exec_seconds,
        }

        job = self._submit_job(payload)
        wait_timeout = max(self.max_exec_seconds, 0.1) + 1.0
        completed = job.event.wait(wait_timeout)
        if not completed:
            return False, None, "Execution timed out"
        if job.result is None:
            return False, None, "Sandbox exited without returning a result"
        return job.result

    def _submit_job(self, payload: Dict[str, Any]) -> _Job:
        if self._shutdown:
            raise RuntimeError("Executor has been shut down")
        job = _Job(payload)
        self._task_queue.put(job)
        return job

    def _start_worker_threads(self) -> None:
        for _ in range(self.max_workers):
            thread = threading.Thread(
                target=self._worker_loop,
                name="azr-exec-worker",
                daemon=True,
            )
            thread.start()
            self._workers.append(thread)

    def _worker_loop(self) -> None:
        while True:
            job = self._task_queue.get()
            if job is None:
                break
            try:
                self._run_job(job)
            finally:
                self._task_queue.task_done()

    def _run_job(self, job: _Job) -> None:
        try:
            completed = subprocess.run(
                [sys.executable, str(self._worker_script)],
                input=pickle.dumps(job.payload),
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                check=False,
                timeout=max(self.max_exec_seconds, 0.1) + 1.0,
            )
        except subprocess.TimeoutExpired:
            job.set_result(False, None, "Execution timed out")
            return
        except Exception as exc:
            job.set_result(False, None, f"Failed to launch sandbox process: {exc}")
            return

        if completed.returncode != 0:
            stderr = completed.stderr.decode("utf-8", "ignore").strip()
            stdout = completed.stdout.decode("utf-8", "ignore").strip()
            message = stderr or stdout or f"Worker exited with code {completed.returncode}"
            job.set_result(False, None, message)
            return

        try:
            status, payload = pickle.loads(completed.stdout)
        except Exception as exc:
            job.set_result(False, None, f"Failed to decode worker response: {exc}")
            return

        if status == "ok":
            job.set_result(True, payload, None)
        elif status == "timeout":
            job.set_result(False, None, "Execution timed out")
        else:
            job.set_result(False, None, str(payload))

    def shutdown(self) -> None:
        if self._shutdown:
            return
        self._shutdown = True
        for _ in self._workers:
            self._task_queue.put(None)
        for thread in self._workers:
            thread.join(timeout=1.0)
        self._workers.clear()
        while not self._task_queue.empty():
            try:
                self._task_queue.get_nowait()
            except queue.Empty:
                break
            finally:
                self._task_queue.task_done()

    def __del__(self):  # pragma: no cover - defensive cleanup
        try:
            self.shutdown()
        except Exception:
            pass


def _run_program_with_timeout(
    program: str,
    inp: Any,
    runs: int,
    timeout_seconds: Optional[float],
) -> Tuple[str, Any]:
    try:
        err = AZRExecutor._static_scan(program)
        if err:
            return "err", err

        safe_globals: Dict[str, Any] = {
            "__builtins__": AZRExecutor.ALLOWED_BUILTINS,
            "__build_class__": _py_builtins.__build_class__,
            "__name__": "__main__",
            "math": math,
        }
        exec(program, safe_globals, safe_globals)
        func = AZRExecutor._discover_callable(safe_globals)
        if func is None:
            return "err", "No callable function found (expected def f(...): ...)"

        max_runs = max(2, runs)
        timer_supported = hasattr(signal, "SIGALRM") and hasattr(signal, "setitimer")
        per_run_timeout = None
        use_timer = False
        previous_handler = None
        if timeout_seconds and timeout_seconds > 0 and timer_supported:
            per_run_timeout = max(timeout_seconds / max_runs, 0.01)
            use_timer = True

            def _raise_timeout(signum, frame):  # type: ignore[unused-argument]
                raise _ExecutionTimeout(f"Execution exceeded {per_run_timeout:.2f}s budget")

            previous_handler = signal.getsignal(signal.SIGALRM)
            signal.signal(signal.SIGALRM, _raise_timeout)

        outputs: List[Any] = []
        try:
            for _ in range(max_runs):
                if use_timer and per_run_timeout is not None:
                    signal.setitimer(signal.ITIMER_REAL, per_run_timeout)
                try:
                    outputs.append(AZRExecutor._call_function(func, deepcopy(inp)))
                except _ExecutionTimeout as exc:
                    return "timeout", str(exc)
                finally:
                    if use_timer:
                        signal.setitimer(signal.ITIMER_REAL, 0.0)
        finally:
            if use_timer:
                signal.setitimer(signal.ITIMER_REAL, 0.0)
                if previous_handler is not None:
                    signal.signal(signal.SIGALRM, previous_handler)

        try:
            pickle.dumps(outputs)
        except Exception as exc:
            return "err", f"Serialization error: {exc}"

        return "ok", outputs
    except Exception:
        return "err", traceback.format_exc()


__all__ = ["AZRExecutor", "_run_program_with_timeout"]
